{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4254913,"sourceType":"datasetVersion","datasetId":2258000}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport os\nfrom tensorflow import keras \nimport glob as gb\nimport pandas as pd\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D ,LeakyReLU","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = (256, 256) # resolution\ndirectory = \"../input/new-bangladeshi-crop-disease/BangladeshiCrops/BangladeshiCrops/Crop___Disease/Corn\"\nBATCH_SIZE = 256\ntrain_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             labels='inferred',\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.1,\n                                             subset='training',\n                                             color_mode='rgb',\n                                             seed=42)\nvalidation_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             labels='inferred',\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=0.1,\n                                             subset='validation',\n                                             color_mode='rgb',\n                                             seed=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_dataset.class_names\nclass_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\nData_imbalance = []\nfor folder in os.listdir(directory):\n    files = gb.glob(pathname=str(directory + \"/\" + folder +\"/*.*\"))\n    Data_imbalance.append(len(files))\nplt.figure(figsize=(13,7))\nsns.barplot(x=[\"Corn Northern Leaf Blight\",\"Corn Healthy \",\"Corn Gray Leaf Spot\",\"Corn Common Rust\"], y=Data_imbalance, palette=\"rocket\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = 0 \nfor i in range(0,len(Data_imbalance)) :\n    total +=Data_imbalance[i] \n    \nweight_for_0 = (1 / Data_imbalance[0]) * (total / 4.0)\nweight_for_1 = (1 / Data_imbalance[1]) * (total / 4.0)\nweight_for_2 = (1 / Data_imbalance[2]) * (total / 4.0)\nweight_for_3 = (1 / Data_imbalance[3]) * (total / 4.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\nprint('Weight for class 2: {:.2f}'.format(weight_for_2))\nprint('Weight for class 3: {:.2f}'.format(weight_for_3))  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip(\"horizontal\"),\n  tf.keras.layers.RandomRotation(0.2),\n  tf.keras.layers.RandomZoom(0.2),\n  tf.keras.layers.RandomHeight(0.2),\n  tf.keras.layers.RandomWidth(0.2),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, _ in train_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] / 255)\n        plt.axis('off')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nCommon_Rust = []\nGray_Leaf_Spot = []\nCorn_Northern_Leaf_Blight =[]\nfor images , labels in train_dataset.take(1):\n    for i in range(100):\n        if class_names[labels[i]] == \"Corn___Common_Rust\":\n            Common_Rust.append(images[i].numpy().astype(\"uint8\"))\n        if  class_names[labels[i]] == \"Corn___Gray_Leaf_Spot\":   \n            Gray_Leaf_Spot.append(images[i].numpy().astype(\"uint8\"))\n        if  class_names[labels[i]] == \"Corn___Northern_Leaf_Blight\":   \n            Corn_Northern_Leaf_Blight.append(images[i].numpy().astype(\"uint8\"))  \nfor i in range(10):            \n    plt.subplot(2,5,i+1)\n    plt.imshow(Common_Rust[i])\n    plt.axis(\"off\")\n    plt.title(\"Corn___Common_Rust\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nfor i in range(10):            \n    plt.subplot(2,5,i+1)\n    plt.imshow(Gray_Leaf_Spot[i])\n    plt.axis(\"off\")\n    plt.title(\"Gray Leaf Spot\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nfor i in range(10):            \n    plt.subplot(2,5,i+1)\n    plt.imshow(Corn_Northern_Leaf_Blight[i])\n    plt.axis(\"off\")\n    plt.title(\"Corn Northern Leaf Blight\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n#IMG_SIZE = (256, 256)  # Remplacer par la taille de vos images\n\ndef Plant_Leaf_Model(image_size):\n    model = models.Sequential([\n        layers.InputLayer(input_shape=image_size + (3,)),\n        \n        layers.Conv2D(32, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Conv2D(128, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n\n        layers.Conv2D(256, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        \n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        \n        \n        \n        layers.Flatten(),\n        layers.Dense(32, activation='relu'),\n        \n        layers.Dense(4, activation='softmax')  # 4 correspond au nombre de classes\n    ])\n\n    model.compile(optimizer='Nadam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    return model\n\n# Créer et résumer le modèle\nmodel = Plant_Leaf_Model(IMG_SIZE)\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_learning_rate = 0.001\nmodel.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=base_learning_rate),\n                           loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                           metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset , verbose=2 , epochs=75 ,class_weight=class_weight,\n                               validation_data=validation_dataset , use_multiprocessing= True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model.save(\"/kaggle/working/my_lstm_model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_dataset , verbose = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 15))\nfor images, labels in train_dataset.take(1):\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")\n        im2 = images[i].numpy().astype(\"uint8\")\n        img2 = tf.expand_dims(im2, 0)\n        predict = model.predict(img2)\n        predicted= class_names[np.argmax(predict)]\n        actual = class_names [labels[i].numpy().astype(\"uint8\")]\n        if (actual == predicted):\n            plt.title(predicted, fontsize=10, color= 'blue', pad=15);\n        else :\n            plt.title(actual, fontsize=10, color= 'red' ,pad=15);  \n        plt.subplots_adjust(left=0.1,bottom=0.1, right=0.9, \n                            top=0.9, wspace=0.4,hspace=0.4)    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = [0.] + history.history['accuracy']\nval_acc = [0.] + history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(17, 12))\nplt.subplot(2, 2, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,3.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}